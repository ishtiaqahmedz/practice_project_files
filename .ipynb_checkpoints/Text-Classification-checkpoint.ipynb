{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976c132e-9ad4-4749-a084-4b862dec6ef6",
   "metadata": {},
   "source": [
    "https://realpython.com/python-keras-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53eb1cd6-97c3-4b44-aceb-b882c15823f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c62af3-17f9-44c4-b24f-9777c7a83704",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict={'yelp':\"data/sentiment_analysis/yelp_labelled.txt\",\n",
    "              'amazon':\"data/sentiment_analysis/yelp_labelled.txt\",\n",
    "              \"imdb\":\"data/sentiment_analysis/yelp_labelled.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b24f6b-bdd1-43a1-9fd3-9dc6b43c05ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yelp': 'data/sentiment_analysis/yelp_labelled.txt',\n",
       " 'amazon': 'data/sentiment_analysis/yelp_labelled.txt',\n",
       " 'imdb': 'data/sentiment_analysis/yelp_labelled.txt'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e76c661-9d88-41d8-9542-1111a7812650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "\n",
    "for source, filepath in filepath_dict.items():\n",
    "    #Name=equence of Hashable, optional Sequence of column labels to apply. If the file contains a header row,\n",
    "    #then you should explicitly pass ``header=0`` to override the column names.\n",
    "    df=pd.read_csv(filepath,names=['sentence', 'label'],sep=\"\\t\")\n",
    "    df['source']=source ## Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "    \n",
    "\n",
    "df=pd.concat(df_list) #Concatenate pandas objects along a particular axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b30bbd2-be80-429f-8080-0d622a68b25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                              sentence  label source\n",
       " 0                             Wow... Loved this place.      1   yelp\n",
       " 1                                   Crust is not good.      0   yelp\n",
       " 2            Not tasty and the texture was just nasty.      0   yelp\n",
       " 3    Stopped by during the late May bank holiday of...      1   yelp\n",
       " 4    The selection on the menu was great and so wer...      1   yelp\n",
       " ..                                                 ...    ...    ...\n",
       " 995  I think food should have flavor and texture an...      0   yelp\n",
       " 996                           Appetite instantly gone.      0   yelp\n",
       " 997  Overall I was not impressed and would not go b...      0   yelp\n",
       " 998  The whole experience was underwhelming, and I ...      0   yelp\n",
       " 999  Then, as if I hadn't wasted enough of my life ...      0   yelp\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       "                                               sentence  label  source\n",
       " 0                             Wow... Loved this place.      1  amazon\n",
       " 1                                   Crust is not good.      0  amazon\n",
       " 2            Not tasty and the texture was just nasty.      0  amazon\n",
       " 3    Stopped by during the late May bank holiday of...      1  amazon\n",
       " 4    The selection on the menu was great and so wer...      1  amazon\n",
       " ..                                                 ...    ...     ...\n",
       " 995  I think food should have flavor and texture an...      0  amazon\n",
       " 996                           Appetite instantly gone.      0  amazon\n",
       " 997  Overall I was not impressed and would not go b...      0  amazon\n",
       " 998  The whole experience was underwhelming, and I ...      0  amazon\n",
       " 999  Then, as if I hadn't wasted enough of my life ...      0  amazon\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       "                                               sentence  label source\n",
       " 0                             Wow... Loved this place.      1   imdb\n",
       " 1                                   Crust is not good.      0   imdb\n",
       " 2            Not tasty and the texture was just nasty.      0   imdb\n",
       " 3    Stopped by during the late May bank holiday of...      1   imdb\n",
       " 4    The selection on the menu was great and so wer...      1   imdb\n",
       " ..                                                 ...    ...    ...\n",
       " 995  I think food should have flavor and texture an...      0   imdb\n",
       " 996                           Appetite instantly gone.      0   imdb\n",
       " 997  Overall I was not impressed and would not go b...      0   imdb\n",
       " 998  The whole experience was underwhelming, and I ...      0   imdb\n",
       " 999  Then, as if I hadn't wasted enough of my life ...      0   imdb\n",
       " \n",
       " [1000 rows x 3 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_list[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "612d614d-864a-49ec-8b1f-4dc4e03bce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Service was very prompt.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  label source\n",
       "0                            Wow... Loved this place.      1   yelp\n",
       "1                                  Crust is not good.      0   yelp\n",
       "2           Not tasty and the texture was just nasty.      0   yelp\n",
       "3   Stopped by during the late May bank holiday of...      1   yelp\n",
       "4   The selection on the menu was great and so wer...      1   yelp\n",
       "5      Now I am getting angry and I want my damn pho.      0   yelp\n",
       "6               Honeslty it didn't taste THAT fresh.)      0   yelp\n",
       "7   The potatoes were like rubber and you could te...      0   yelp\n",
       "8                           The fries were great too.      1   yelp\n",
       "9                                      A great touch.      1   yelp\n",
       "10                           Service was very prompt.      1   yelp"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02214c-8fcf-4ccc-a266-bae778c0040e",
   "metadata": {},
   "source": [
    "The resulting vector is also called a feature vector. In a feature vector, each dimension can be a numeric or categorical feature, like for example the height of a building, the price of a stock, or, in our case, the count of a word in a vocabulary.\n",
    "Let’s quickly illustrate this. Imagine you have the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b3edf2-4c27-4122-b1cc-a7e6ec79923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "102a5934-c1a8-4698-ac36-b249be5a8182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#(we used it in our Recommender System)\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer(min_df=0.0,lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1f3cd-cce2-4118-8583-9a4d67198913",
   "metadata": {},
   "source": [
    "This vocabulary serves also as an index of each word. Now, you can take each sentence and get the word occurrences of the words based on the previous vocabulary. The vocabulary consists of all five words in our sentences, each representing one word in the vocabulary.When you take the previous two sentences and transform them with the CountVectorizer you will get a vector representing the count of each word of the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "345d4686-9f22-4008-b33d-631cf201341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515150c-48a4-4c21-a0a7-6c888a89c8b0",
   "metadata": {},
   "source": [
    "This is considered a Bag-of-words (BOW) model, which is a common way in NLP to create vectors out of text.Each document is represented as a vector. You can use these vectors now as feature vectors for a machine learning model. This leads us to our next part, defining a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07484bf3-3c20-45f4-b8ff-ac975945a502",
   "metadata": {},
   "source": [
    "## Defining a Baseline Model:\n",
    "\r\n",
    "When you work with machine learning, one important step is to define a baseline model. This usually involves a simple model, which is then used as a comparison with the more advanced models that you want to test. In this case, you’ll use the baseline model to compare it to the more advanced methods involving (deep) neural networks, the meat and potatoes of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc52b7-e0d0-4884-96f8-0cecb484c53e",
   "metadata": {},
   "source": [
    "We start by taking the Yelp data set which we extract from our concatenated data set. From there, we take the sentences and labels. The .values returns a NumPy array instead of a Pandas Series object which is in this context easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43fefeac-ddb1-4d7f-97aa-2e753fc39547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df_yelp=df[df['source']=='yelp']\n",
    "sentences=df_yelp['sentence'].values\n",
    "y=df_yelp['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46f9f10e-d9ce-4348-b9d7-62aa62dbe36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Wow... Loved this place.', 'Crust is not good.',\n",
       "        'Not tasty and the texture was just nasty.',\n",
       "        'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       "        'The selection on the menu was great and so were the prices.'],\n",
       "       dtype=object),\n",
       " array([1, 0, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0:5],y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b63f92b-7501-4c64-bab2-fce3be03d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test=train_test_split(sentences,y,test_size=0.25,random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fc954-dd30-4381-8916-5ac2aae0fdc9",
   "metadata": {},
   "source": [
    "Here we will use again on the previous BOW model to vectorize the sentences. You can use again the CountVectorizer for this task. Since you might not have the testing data available during training, you can create the vocabulary using only the training data. Using this vocabulary, you can create the feature vectors for each sentence of the training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1f0e31e-5a4b-4371-93a5-977106bf164c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x1938 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7453 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "#teansformer:Transform documents to document-term matrix. Extract token counts out of raw text documents using the vocabulary\n",
    "#fitted with fit or the one provided to the constructor.\n",
    "    \n",
    "X_train=vectorizer.transform(sentences_train)\n",
    "X_test=vectorizer.transform(sentences_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb8603-a4e6-4695-86c7-23a12268728e",
   "metadata": {},
   "source": [
    "You can see that the resulting feature vectors have 750 samples which are the number of training samples we have after the train-test split. Each sample has 2505 dimensions which is the size of the vocabulary. Also, you can see that we get a sparse matrix. This is a data type that is optimized for matrices with only a few non-zero elements, which only keeps track of the non-zero elements reducing the memory load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610e035-897c-4f4a-9ac3-3a3068ee33a0",
   "metadata": {},
   "source": [
    "CountVectorizer performs tokenization which separates the sentences into a set of tokens as you saw previously in the vocabulary. It additionally removes punctuation and special characters and can apply other preprocessing to each word. If you want, you can use a custom tokenizer from the NLTK library with the CountVectorizer or use any number of the customizations which you can explore to improve the performance of your model. The classification model we are going to use is the logistic regression which is a simple yet powerful linear mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c602fbbe-eade-498d-97fe-0c564c5f90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "classifier=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea23103-b568-44e2-879a-9ba764d81be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.772\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)\n",
    "score=classifier.score(X_test,y_test)\n",
    "\n",
    "print(\"Accuracy score:\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1876e-bcbf-40f1-b7b4-d9acf99953dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
