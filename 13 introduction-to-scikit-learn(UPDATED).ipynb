{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Quick Machine Learning Modelling Tutorial with Python and Scikit-Learn \n",
    "This notebook goes through a range of common and useful featues of the Scikit-Learn library.\n",
    "\n",
    "It's long but it's called quick because of how vast the Scikit-Learn library is. Covering everything requires a [full-blown documentation](https://scikit-learn.org/stable/user_guide.html), of which, if you ever get stuck, you should read.\n",
    "\n",
    "## What is Scikit-Learn (sklearn)?\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/index.html), also referred to as `sklearn`, is an open-source Python machine learning library.\n",
    "\n",
    "It's built on top on NumPy (Python library for numerical computing) and Matplotlib (Python library for data visualization).\n",
    "\n",
    "<img src=\"../project_files/images/sklearn-6-step-ml-framework-tools-scikit-learn-highlight.png\" alt=\"a 6 step machine learning framework along will tools you can use for each step\" width=\"700\"/>\n",
    "\n",
    "## Why Scikit-Learn?\n",
    "\n",
    "Although the field of machine learning is vast, the main goal is finding patterns within data and then using those patterns to make predictions.\n",
    "\n",
    "And there are certain categories which a majority of problems fall into.\n",
    "\n",
    "If you're trying to create a machine learning model to predict whether an email is spam and or not spam, you're working on a classification problem (whether something is something(s) or another).\n",
    "\n",
    "If you're trying to create a machine learning model to predict the price of houses given their characteristics, you're working on a regression problem (predicting a number).\n",
    "\n",
    "Once you know what kind of problem you're working on, there are also similar steps you'll take for each. Steps like splitting the data into different sets, one for your machine learning algorithms to learn on and another to test them on.\n",
    "Choosing a machine learning model and then evaluating whether or not your model has learned anything.\n",
    "\n",
    "Scikit-Learn offers Python implementations for doing all of these kinds of tasks. Saving you having to build them from scratch.\n",
    "\n",
    "\n",
    "## What does this notebook cover?\n",
    "\n",
    "The Scikit-Learn library is very capable. However, learning everything off by heart isn't necessary. Instead, this notebook focuses some of the main use cases of the library.\n",
    "\n",
    "More specifically, we'll cover:\n",
    "\n",
    "<img src=\"../images/sklearn-workflow-title.png\" alt=\"a 6 step scikit-learn workflow\"/>\n",
    "\n",
    "0. An end-to-end Scikit-Learn worfklow\n",
    "1. Getting the data ready\n",
    "2. Choosing the right maching learning estimator/aglorithm/model for your problem\n",
    "3. Fitting your chosen machine learning model to data and using it to make a prediction\n",
    "4. Evaluting a machine learning model\n",
    "5. Improving predictions through experimentation (hyperparameter tuning)\n",
    "6. Saving and loading a pretrained model\n",
    "7. Putting it all together in a pipeline\n",
    "\n",
    "**Note:** all of the steps in this notebook are focused on **supervised learning** (having data and labels).\n",
    "\n",
    "After going through it, you'll have the base knolwedge of Scikit-Learn you need to keep moving forward.\n",
    "\n",
    "## Where can I get help?\n",
    "If you get stuck or think of something you'd like to do which this notebook doesn't cover, don't fear!\n",
    "\n",
    "The recommended steps you take are:\n",
    "1. **Try it** - Since Scikit-Learn has been designed with usability in mind, your first step should be to use what you know and try figure out the answer to your own question (getting it wrong is part of the process). If in doubt, run your code.\n",
    "2. **Press SHIFT+TAB** - See you can the docstring of a function (information on what the function does) by pressing **SHIFT + TAB** inside it. Doing this is a good habit to develop. It'll improve your research skills and give you a better understanding of the library. \n",
    "3. **Search for it** - If trying it on your own doesn't work, since someone else has probably tried to do something similar, try searching for your problem. You'll likely end up in 1 of 2 places:\n",
    "    * [Scikit-Learn documentation/user guide](https://scikit-learn.org/stable/user_guide.html) - the most extensive resource you'll find for Scikit-Learn information.\n",
    "    * [Stack Overflow](https://stackoverflow.com/) - this is the developers Q&A hub, it's full of questions and answers of different problems across a wide range of software development topics and chances are, there's one related to your problem.\n",
    "    \n",
    "An example of searching for a Scikit-Learn solution might be:\n",
    "\n",
    "> \"how to tune the hyperparameters of a sklearn model\"\n",
    "\n",
    "Searching this on Google leads to the Scikit-Learn documentation for the `GridSearchCV` function: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n",
    "The next steps here are to read through the documentation, check the examples and see if they line up to the problem you're trying to solve. If they do, **rewrite the code** to suit your needs, run it, and see what the outcomes are.\n",
    "\n",
    "4. **Ask for help** - If you've been through the above 3 steps and you're still stuck, you might want to ask your question on [Stack Overflow](https://www.stackoverflow.com). Be as specific as possible and provide details on what you've tried.\n",
    "\n",
    "Remember, you don't have to learn all of the functions off by heart to begin with. \n",
    "\n",
    "What's most important is continually asking yourself, \"what am I trying to do with the data?\".\n",
    "\n",
    "Start by answering that question and then practicing finding the code which does it.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow\n",
    "\n",
    "Before we get in-depth, let's quickly check out what an end-to-end Scikit-Learn workflow might look like.\n",
    "\n",
    "Once we've seen an end-to-end workflow, we'll dive into each step a little deeper.\n",
    "\n",
    "**Note:** Since Scikit-Learn is such a vast library, capable of tackling many problems, the workflow we're using is only one example of how you can use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Workflow for Classifying Heart Disease\n",
    "\n",
    "#### 1. Get the data ready\n",
    "\n",
    "As an example dataset, we'll import `heart-disease.csv`. This file contains anonymised patient medical records and whether or not they have heart disease or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv('../project_files/data/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row is a different patient and all columns except `target` are different patient characteristics. `target` indicates whether the patient has heart disease (`target` = 1) or not (`target` = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X (all the feature columns)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Create y (the target column)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: target, dtype: int64,\n",
       " target\n",
       " 1    165\n",
       " 0    138\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Choose the model and hyperparameters\n",
    "This is often referred to as `model` or `clf` (short for classifier) or estimator (as in the Scikit-Learn) documentation.\n",
    "\n",
    "Hyperparameters are like knobs on an oven you can tune to cook your favourite dish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll leave the hyperparameters as default to begin with...\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fit the model to the data and use it to make a prediction\n",
    "Fitting the model on the data involves passing it the data and asking it to figure out the patterns. \n",
    "\n",
    "If there are labels (supervised learning), the model tries to work out the relationship between the data and the labels. \n",
    "\n",
    "If there are no labels (unsupervised learning), the model tries to find patterns and group similar samples together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the model to make a prediction\n",
    "\n",
    "The whole point of training a machine learning model is to use it to make some kind of prediction in the future.\n",
    "\n",
    "Once our model instance is trained, you can use the `predict()` method to predict a target value given a set of features. In other words, use the model, along with some unlabelled data to predict the label. \n",
    "\n",
    "Note, data you predict on has to be in the same shape as data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This doesn't work... incorrect shapes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m             )\n\u001b[1;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# This doesn't work... incorrect shapes\n",
    "y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "57    45    1   0       115   260    0        0      185      0      0.0   \n",
       "54    63    0   2       135   252    0        0      172      0      0.0   \n",
       "222   65    1   3       138   282    1        0      174      0      1.4   \n",
       "129   74    0   1       120   269    0        0      121      1      0.2   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "57       2   0     2  \n",
       "54       2   0     2  \n",
       "222      1   1     2  \n",
       "129      2   1     2  \n",
       "279      1   1     2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to predict a label, data has to be in the same shape as X_train\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a prediction on the test data (further evaluation)\n",
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluate the model\n",
    "\n",
    "Now we've made some predictions, we can start to use some more Scikit-Learn methods to figure out how good our model is. \n",
    "\n",
    "Each model or estimator has a built-in score method. This method compares how well the model was able to learn the patterns between the features and labels. In other words, it returns how accurate your model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7763157894736842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a number of other evaluation methods we can use for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75        33\n",
      "           1       0.81      0.79      0.80        43\n",
      "\n",
      "    accuracy                           0.78        76\n",
      "   macro avg       0.77      0.77      0.77        76\n",
      "weighted avg       0.78      0.78      0.78        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From NG Andrew Lessons: \n",
    "\n",
    "In scewed classes, it becomes more harder to use just classification accuraccy, so we use Precesion/Recall Error Matric \n",
    "\n",
    "Precision: out of predicted positives, how many are True Positives (actually have the disease): \n",
    "Precision= True Positives / True Positives + False Positives \n",
    "\n",
    "\n",
    "Recall: Out of actual positives (actual patients), how many were diagnosed correctly.\n",
    "Recall= True Positives/ True Positives+False Negatives \n",
    "\n",
    "\n",
    "(Note:False negatives is the patients which we classified as negatives but they were positives)\n",
    "\n",
    "\n",
    "F1 Score = 2 (PR/P+R)\n",
    "\n",
    "\n",
    "** ZTM Lecture: **\n",
    "- The precision will be \"how many are correctly classified among that class\"\n",
    "- The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "- The f1-score is the harmonic mean between precision & recall\n",
    "- The support is the number of occurence of the given class in your dataset (so you have 37.5K of class 0 and 37.5K of class 1, which is a really well balanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  8],\n",
       "       [ 9, 34]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7763157894736842"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Experiment to improve\n",
    "\n",
    "The first model you build is often referred to as a baseline.\n",
    "\n",
    "Once you've got a baseline model, like we have here, it's important to remember, this is often not the final model you'll use.\n",
    "\n",
    "The next step in the workflow is to try and improve upon your baseline model.\n",
    "\n",
    "And to do this, there's two ways to look at it. From a model perspective and from a data perspective.\n",
    "\n",
    "From a model perspective this may involve things such as using a more complex model or tuning your models hyperparameters.\n",
    "\n",
    "From a data perspective, this may involve collecting more data or better quality data so your existing model has more of a chance to learn the patterns within.\n",
    "\n",
    "If you're already working on an existing dataset, it's often easier try a series of model perspective experiments first and then turn to data perspective experiments if you aren't getting the results you're looking for.\n",
    "\n",
    "**One thing you should be aware of is if you're tuning a models hyperparameters in a series of experiments, your reuslts should always be cross-validated. Cross-validation is a way of making sure the results you're getting are consistent across your training and test datasets (because it uses multiple versions of training and test sets) rather than just luck because of the order the original training and test sets were created.** \n",
    "\n",
    "\n",
    "Cross-validation: It's a resampling technique that splits the data into several subsets and then uses each subset to train and test the model. Cross-validation checks how well a model works on data it hasn't seen before. This is done to avoid overfitting problems\n",
    "\n",
    "\n",
    "* Try different hyperparameters\n",
    "* All different parameters should be cross-validated \n",
    "    * **Note:** Beware of cross-validation for time series problems \n",
    "    \n",
    "Different models you use will have different hyperparameters you can tune. For the case of our model, the `RandomForestClassifier()`, we'll start trying different values for `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 67.10526315789474%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 76.31578947368422%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 76.31578947368422%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 76.31578947368422%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 75.0%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 73.68421052631578%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 75.0%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 80.26315789473685%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try different numbers of estimators (trees)... (no cross-validation)\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * n_estimators: *\n",
    "the number of decision trees in the forest. Increasing this hyperparameter generally improves the performance of the model but also increases the computational cost of training and predicting. \n",
    "- max_depth: the maximum depth of each decision tree in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 10 estimators...\n",
      "Model accuracy on test set: 67.10526315789474%\n",
      "Cross-validation score: 78.53551912568305%\n",
      "\n",
      "Trying model with 20 estimators...\n",
      "Model accuracy on test set: 77.63157894736842%\n",
      "Cross-validation score: 79.84699453551912%\n",
      "\n",
      "Trying model with 30 estimators...\n",
      "Model accuracy on test set: 73.68421052631578%\n",
      "Cross-validation score: 80.50819672131148%\n",
      "\n",
      "Trying model with 40 estimators...\n",
      "Model accuracy on test set: 71.05263157894737%\n",
      "Cross-validation score: 82.15300546448088%\n",
      "\n",
      "Trying model with 50 estimators...\n",
      "Model accuracy on test set: 78.94736842105263%\n",
      "Cross-validation score: 81.1639344262295%\n",
      "\n",
      "Trying model with 60 estimators...\n",
      "Model accuracy on test set: 77.63157894736842%\n",
      "Cross-validation score: 83.47540983606557%\n",
      "\n",
      "Trying model with 70 estimators...\n",
      "Model accuracy on test set: 73.68421052631578%\n",
      "Cross-validation score: 81.83060109289617%\n",
      "\n",
      "Trying model with 80 estimators...\n",
      "Model accuracy on test set: 76.31578947368422%\n",
      "Cross-validation score: 82.81420765027322%\n",
      "\n",
      "Trying model with 90 estimators...\n",
      "Model accuracy on test set: 76.31578947368422%\n",
      "Cross-validation score: 82.81967213114754%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# With cross-validation\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100}%\")\n",
    "    print(f\"Cross-validation score: {np.mean(cross_val_score(model, X, y, cv=5)) * 100}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to do it with GridSearchCV...\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameters to search over\n",
    "param_grid = {'n_estimators': [i for i in range(10, 100, 10)]}\n",
    "\n",
    "# Setup the grid search\n",
    "grid = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Find the best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=80)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=80)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to be the best estimator\n",
    "clf = grid.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model scores\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Save a model for someone else to use\n",
    "\n",
    "When you've done a few experiments and you're happy with how your model is doing, you'll likely want someone else to be able to use it.\n",
    "\n",
    "This may come in the form of a teammate or colleague trying to replicate and validate your results or through a customer using your model as part of a service or application you offer.\n",
    "\n",
    "Saving a model also allows you to reuse it later without having to go through retraining it. Which is helpful, especially when your training times start to increase.\n",
    "\n",
    "You can save a scikit-learn model using Python's in-built `pickle` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(model, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a saved model and make a prediction\n",
    "loaded_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting the data ready\n",
    "\n",
    "Data doesn't always come ready to use with a Scikit-Learn machine learning model.\n",
    "\n",
    "Three of the main steps you'll often have to take are:\n",
    "* Splitting the data into features (usually `X`) and labels (usually `y`)\n",
    "* Filling (also called imputing) or disregarding the missing values\n",
    "* Converting non-numerical values to numerical values (also call feature encoding)\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into X & y\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heart_disease.drop('target', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, Length: 303, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = heart_disease['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2) # you can change the test size\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% of data is being used for the test set \n",
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Make sure it's all numerical\n",
    "We want to turn the `\"Make\"` and `\"Colour\"` columns into numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820</td>\n",
       "      <td>4</td>\n",
       "      <td>32042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>155144</td>\n",
       "      <td>3</td>\n",
       "      <td>5716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604</td>\n",
       "      <td>4</td>\n",
       "      <td>31570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883</td>\n",
       "      <td>4</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360</td>\n",
       "      <td>4</td>\n",
       "      <td>12732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors  Price\n",
       "0     Honda  White          35431      4  15323\n",
       "1       BMW   Blue         192714      5  19943\n",
       "2     Honda  White          84714      4  28343\n",
       "3    Toyota  White         154365      4  13434\n",
       "4    Nissan   Blue         181577      3  14043\n",
       "..      ...    ...            ...    ...    ...\n",
       "995  Toyota  Black          35820      4  32042\n",
       "996  Nissan  White         155144      3   5716\n",
       "997  Nissan   Blue          66604      4  31570\n",
       "998   Honda  White         215883      4   4001\n",
       "999  Toyota   Blue         248360      4  12732\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car-sales-extended.csv\n",
    "car_sales = pd.read_csv(\"../project_files/data/car-sales-extended.csv\")\n",
    "car_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             object\n",
       "Colour           object\n",
       "Odometer (KM)     int64\n",
       "Doors             int64\n",
       "Price             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y and train/test\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and build a model on our `car_sales` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Nissan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28508\\1044518071.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Try to predict with random forest on price column (doesn't work)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 )\n\u001b[0;32m   1388\u001b[0m             ):\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         X, y = validate_data(\n\u001b[0m\u001b[0;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2957\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2961\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         )\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1052\u001b[0m                         )\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n\u001b[0;32m   1058\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\AI Local\\practice_projects\\Bulldozer_Price\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Nissan'"
     ]
    }
   ],
   "source": [
    "# Try to predict with random forest on price column (doesn't work)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops... this doesn't work, we'll have to convert it to numbers first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code to show image, from the image folder, in the markdown cell\n",
    "\n",
    "#One-hot encoding is essentially the representation of categorical variables as binary vectors. These categorical values are first mapped to integer values. Each integer value is then represented as a binary vector\n",
    "\n",
    "\n",
    "<img src=\"images/one-hot-encoding.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical features\n",
    "\n",
    "**ORDINAL ENCORDER**\n",
    "\n",
    "\n",
    "Often features are not given as continuous values but categorical. \n",
    "\n",
    "For example a person could have features [\"male\", \"female\"], [\"from Europe\", \"from US\", \"from Asia\"], [\"uses Firefox\", \"uses Chrome\", \"uses Safari\", \"uses Internet Explorer\"]. Such features can be efficiently coded as integers, for instance [\"male\", \"from US\", \"uses Internet Explorer\"] could be expressed as [0, 1, 3] while [\"female\", \"from Asia\", \"uses Chrome\"] would be [1, 2, 1].\n",
    "\n",
    "\n",
    "To convert categorical features to such integer codes, we can use the OrdinalEncoder. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):\n",
    "\n",
    "Such integer representation can, however, **not** be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).\n",
    "\n",
    "\n",
    "**ONE-HOT-ENCODER**\n",
    "\n",
    "For categorical variables where no such ordinal relationship exists, the integer encoding is not enough.\n",
    "\n",
    "In fact, using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n",
    "\n",
    "In this case, a one-hot encoding can be applied to the integer representation\n",
    "\n",
    "\n",
    "\n",
    "(Another possibility to convert categorical features to features that can be used with scikit-learn estimators is to use a one-of-K, also known as one-hot or dummy encoding. This type of encoding can be obtained with the OneHotEncoder, which transforms each categorical feature with n_categories possible values into n_categories binary features, with one of them 1, and all others 0)\n",
    "\n",
    "Continuing the example above:\n",
    "\n",
    ">>> enc = preprocessing.OneHotEncoder()\n",
    ">>> \n",
    ">>> X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    ">>> \n",
    ">>> enc.fit(X)\n",
    ">>> \n",
    ">>> OneHotEncoder()\n",
    ">>>\n",
    "\n",
    ">>> enc.transform([['female', 'from US', 'uses Safari'],\n",
    "                  ['male', 'from Europe', 'uses Safari']]).toarray()\n",
    "\n",
    "\n",
    "array([[1., 0., 0., 1., 0., 1.],\n",
    "       [0., 1., 1., 0., 0., 1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if test data has a new category that trained data never seen?\n",
    "\n",
    "### What onehotencoder would do in that case?\n",
    "When the test data contains a new category that wasn't seen in the training data, the behavior of OneHotEncoder depends on its configuration:\n",
    "\n",
    "If configured with handle_unknown='ignore':\n",
    "The encoder will output a row of all zeros for that new category. This maintains the same feature dimensions as the training data and avoids errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]], shape=(1000, 13))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 3.5431e+04])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             Honda\n",
       "Colour           White\n",
       "Odometer (KM)    35431\n",
       "Doors                4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431</td>\n",
       "      <td>4</td>\n",
       "      <td>15323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714</td>\n",
       "      <td>5</td>\n",
       "      <td>19943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714</td>\n",
       "      <td>4</td>\n",
       "      <td>28343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365</td>\n",
       "      <td>4</td>\n",
       "      <td>13434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577</td>\n",
       "      <td>3</td>\n",
       "      <td>14043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors  Price\n",
       "0   Honda  White          35431      4  15323\n",
       "1     BMW   Blue         192714      5  19943\n",
       "2   Honda  White          84714      4  28343\n",
       "3  Toyota  White         154365      4  13434\n",
       "4  Nissan   Blue         181577      3  14043"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way... using pandas and pd.get_dummies()\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doors</th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Doors  Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0        4     False        True        False        False         False   \n",
       "1        5      True       False        False        False         False   \n",
       "2        4     False        True        False        False         False   \n",
       "3        4     False       False        False         True         False   \n",
       "4        3     False       False         True        False         False   \n",
       "..     ...       ...         ...          ...          ...           ...   \n",
       "995      4     False       False        False         True          True   \n",
       "996      3     False       False         True        False         False   \n",
       "997      4     False       False         True        False         False   \n",
       "998      4     False        True        False        False         False   \n",
       "999      4     False       False        False         True         False   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  \n",
       "0          False         False       False          True  \n",
       "1           True         False       False         False  \n",
       "2          False         False       False          True  \n",
       "3          False         False       False          True  \n",
       "4           True         False       False         False  \n",
       "..           ...           ...         ...           ...  \n",
       "995        False         False       False         False  \n",
       "996        False         False       False          True  \n",
       "997         True         False       False         False  \n",
       "998        False         False       False          True  \n",
       "999         True         False       False         False  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make_BMW</th>\n",
       "      <th>Make_Honda</th>\n",
       "      <th>Make_Nissan</th>\n",
       "      <th>Make_Toyota</th>\n",
       "      <th>Colour_Black</th>\n",
       "      <th>Colour_Blue</th>\n",
       "      <th>Colour_Green</th>\n",
       "      <th>Colour_Red</th>\n",
       "      <th>Colour_White</th>\n",
       "      <th>Doors_3</th>\n",
       "      <th>Doors_4</th>\n",
       "      <th>Doors_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make_BMW  Make_Honda  Make_Nissan  Make_Toyota  Colour_Black  \\\n",
       "0       False        True        False        False         False   \n",
       "1        True       False        False        False         False   \n",
       "2       False        True        False        False         False   \n",
       "3       False       False        False         True         False   \n",
       "4       False       False         True        False         False   \n",
       "..        ...         ...          ...          ...           ...   \n",
       "995     False       False        False         True          True   \n",
       "996     False       False         True        False         False   \n",
       "997     False       False         True        False         False   \n",
       "998     False        True        False        False         False   \n",
       "999     False       False        False         True         False   \n",
       "\n",
       "     Colour_Blue  Colour_Green  Colour_Red  Colour_White  Doors_3  Doors_4  \\\n",
       "0          False         False       False          True    False     True   \n",
       "1           True         False       False         False    False    False   \n",
       "2          False         False       False          True    False     True   \n",
       "3          False         False       False          True    False     True   \n",
       "4           True         False       False         False     True    False   \n",
       "..           ...           ...         ...           ...      ...      ...   \n",
       "995        False         False       False         False    False     True   \n",
       "996        False         False       False          True     True    False   \n",
       "997         True         False       False         False    False     True   \n",
       "998        False         False       False          True    False     True   \n",
       "999         True         False       False         False    False     True   \n",
       "\n",
       "     Doors_5  \n",
       "0      False  \n",
       "1       True  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  \n",
       "..       ...  \n",
       "995    False  \n",
       "996    False  \n",
       "997    False  \n",
       "998    False  \n",
       "999    False  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have to convert doors to object for dummies to work on it...\n",
    "car_sales[\"Doors\"] = car_sales[\"Doors\"].astype(object)\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make\n",
       "Toyota    398\n",
       "Honda     304\n",
       "Nissan    198\n",
       "BMW       100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categorical categories are now either 1 or 0...\n",
    "X[\"Make\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235867221569877"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What if there were missing values?\n",
    "\n",
    "Many machine learning models don't work well when there are missing values in the data.\n",
    "\n",
    "There are two main options when dealing with missing values.\n",
    "\n",
    "1. Fill them with some given value. For example, you might fill missing values of a numerical column with the mean of all the other values. The practice of filling missing values is often referred to as imputation.\n",
    "2. Remove them. If a row has missing values, you may opt to remove them completely from your sample completely. However, this potentially results in using less data to build your model.\n",
    "\n",
    "**Note:** Dealing with missing values is a problem to problem issue. And there's often no best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import car sales dataframe with missing values\n",
    "car_sales_missing = pd.read_csv(\"../project_files/data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 5000 stored elements and shape (1000, 17)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's convert the categorical columns to one hot encoded (code copied from above)\n",
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh... this doesn't work. We'll have to either fill or remove the missing values.\n",
    "\n",
    "Let's see what values are missing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Fill missing data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'll do is fill the rows where categorical values are missing with `\"missing\"`, the numerical features with the mean or 4 for the doors. And drop the rows where the Price is missing. \n",
    "\n",
    "We could fill Price with the mean, however, since it's the target variable, we don't want to be introducing too many fake labels.\n",
    "\n",
    "**Note:** The practice of filling missing data is called **imputation** (Imputation Def: The assignment of a value to something by inference from the value of the products or processes to which it contributes). \n",
    "\n",
    "And it's important to remember there's no perfect way to fill missing data. The methods we're using are only one of many. The techniques you use will depend heavily on your dataset. A good place to look would be searching for \"data imputation techniques\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilawar Khan\\AppData\\Local\\Temp\\ipykernel_28508\\3915909080.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill the \"Make\" column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilawar Khan\\AppData\\Local\\Temp\\ipykernel_28508\\1669573930.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill the \"Colour\" column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilawar Khan\\AppData\\Local\\Temp\\ipykernel_28508\\2042374414.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill the \"Odometer (KM)\" column\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilawar Khan\\AppData\\Local\\Temp\\ipykernel_28508\\3365304401.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  car_sales_missing[\"Doors\"].fillna(4, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill the \"Doors\" column\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our dataframe\n",
    "car_sales_missing.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Price labels\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've removed the rows with missing Price values, now there's less data but there's no more missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]], shape=(950, 16))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one-hot encode the categorical columns (copied from above)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 3.5431e+04,\n",
       "       1.5323e+04])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Filling missing data and transforming categorical data with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've filled the missing columns using pandas functions, you might be thinking, \"Why pandas? I thought this was a Scikit-Learn introduction?\".\n",
    "\n",
    "Not to worry, scikit-learn provides another method called [`SimpleImputer()`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) which allows us to do a similar thing.\n",
    "\n",
    "`SimpleImputer()` transforms data by filling missing values with a given strategy.\n",
    "\n",
    "And we can use it to fill the missing values in our DataFrame as above.\n",
    "\n",
    "At the moment, our dataframe has no mising values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reimport it so it has missing values and we can fill them with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reimport the DataFrame\n",
    "car_sales_missing = pd.read_csv(\"../project_files/data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing in the \"Price\" column\n",
    "car_sales_missing.dropna(subset=[\"Price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis=1)\n",
    "y = car_sales_missing[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We split data into train & test to perform filling missing values on them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill categorical values with 'missing' & numerical with mean\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different column features\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "numerical_feature = [\"Odometer (KM)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We use `fit_transform()` on the training data and `transform()` on the testing data. In essence, we learn the patterns in the training set and transform it via imputation (fit, then transform). Then we take those same patterns and fill the test set (transform only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 71934.0],\n",
       "       ['Toyota', 'Red', 4.0, 162665.0],\n",
       "       ['Honda', 'White', 4.0, 42844.0],\n",
       "       ...,\n",
       "       ['Toyota', 'White', 4.0, 196225.0],\n",
       "       ['Honda', 'Blue', 4.0, 133117.0],\n",
       "       ['Honda', 'missing', 4.0, 150582.0]], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = ColumnTransformer([\n",
    "    (\"cat_imputer\", cat_imputer, categorical_features),\n",
    "    (\"door_imputer\", door_imputer, door_feature),\n",
    "    (\"num_imputer\", num_imputer, numerical_feature)])\n",
    "\n",
    "# Fill train and test values separately\n",
    "filled_X_train = imputer.fit_transform(X_train)\n",
    "filled_X_test = imputer.transform(X_test)\n",
    "\n",
    "# Check filled X_train\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our transformed data array's back into DataFrame's\n",
    "car_sales_filled_train = pd.DataFrame(filled_X_train, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "# Check missing data in training set\n",
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see the original... still missing values\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the categorical columns to one hot encoded (code copied from above)\n",
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "transformed_X = transformer.fit_transform(car_sales_missing)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 7.19340e+04],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.62665e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 4.28440e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.96225e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.33117e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.50582e+05]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's one hot encode the features with the same code as before \n",
    "\n",
    "\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\", \n",
    "                                 one_hot, \n",
    "                                 categorical_features)],\n",
    "                                 remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train)\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test)\n",
    "\n",
    "# Check transformed and filled X_train\n",
    "transformed_X_train.toarray() #the three columns of df will be transformed and others will remain the same. The array is retured after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transformed_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21229043336119102"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Make sure to use transformed (filled and one-hot encoded X data)\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this looks confusing, don't worry, we've covered a lot of ground very quickly. And we'll revisit these strategies in a future section in way which makes a lot more sense.\n",
    "\n",
    "For now, the key takeaways to remember are:\n",
    "* Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "* For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as **feature engineering** or **feature encoding**.\n",
    "* Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as **data imputation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for your problem\n",
    "\n",
    "Once you've got your data ready, the next step is to choose an appropriate machine learning algorithm or model to find patterns in your data.\n",
    "\n",
    "Some things to note:\n",
    "* Sklearn refers to machine learning models and algorithms as estimators.\n",
    "* Classification problem - predicting a category (heart disease or not).\n",
    "    * Sometimes you'll see `clf` (short for classifier) used as a classification estimator instance's variable name.\n",
    "* Regression problem - predicting a number (selling price of a car).\n",
    "* Unsupervised problem - clustering (grouping unlabelled samples with other similar unlabelled samples).\n",
    "\n",
    "If you know what kind of problem you're working with, one of the next places you should look at is the [Scikit-Learn algorithm cheatsheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "This cheatsheet gives you a bit of an insight into the algorithm you might want to use for the problem you're working on.\n",
    "\n",
    "It's important to remember, you don't have to explicitly know what each algorithm is doing on the inside to start using them. If you do start to apply different algorithms but they don't seem to be working, that's when you'd start to look deeper into each one.\n",
    "\n",
    "Let's check out the cheatsheet and follow it for some of the problems we're working on.\n",
    "\n",
    "<img src=\"../project_files/images/sklearn-ml-map.png\" width=700/>\n",
    "\n",
    "You can see it's split into four main categories. Regression, classification, clustering and dimensionality reduction. Each has their own different purpose but the Scikit-Learn team has designed the library so the workflows for each are relatively similar.\n",
    "\n",
    "Let's start with a regression problem (trying to predict a number). We'll use the [California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) built into Scikit-Learn's `datasets` module.\n",
    "\n",
    "The goal of the California Housing dataset is to predict a given district's median house value (in hundreds of thousands of dollars) on things like the age of the home, the number of rooms, the number of bedrooms, number of people living the home and more.\n",
    "\n",
    "### 2.1 Picking a machine learning model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get California Housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing; # gets downloaded as dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's in a dictionary, let's turn it into a DataFrame so we can inspect it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = pd.Series(housing[\"target\"])\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20640"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples?\n",
    "len(housing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, our goal here is to use the feature columns, such as:\n",
    "* `MedInc` - median income in block group\n",
    "* `HouseAge` - median house age in block group\n",
    "* `AveRooms` - average number of rooms per household\n",
    "* `AveBedrms` - average number of bedrooms per household\n",
    "\n",
    "To predict the `target` column which expresses the median house value for specfici California districts in hundreds of thousands of dollars ($100,000). \n",
    "\n",
    "In essence, each row is a different district in California (the data) and we're trying to build a model to predict the median house value in that distract (the target/label) given a series of attributes about the houses in that district.\n",
    "\n",
    "Since we have data and labels, this is a supervised learning problem. And since we're trying to predict a number, it's a regression problem.\n",
    "\n",
    "Knowing these two things, how do they line up on the Scikit-Learn machine learning algorithm cheat-sheet?\n",
    "\n",
    "<img src=\"../project_files/images/sklearn-ml-map-cheatsheet-california-housing-ensemble.png\" width=700/>\n",
    "\n",
    "Following the map through, knowing what we know, it suggests we try [`RidgeRegression`](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression). Let's chek it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440125"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Ridge model class from the linear_model module\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score() metirc of regression aglorithms is R^2\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if `RidgeRegression` didn't work? Or what if we wanted to improve our results?\n",
    "\n",
    "<img src=\"../project_files/images/sklearn-ml-map-cheatsheet-california-housing-ensemble.png\" width=700/>\n",
    "\n",
    "Following the diagram, the next step would be to try [`EnsembleRegressors`](https://scikit-learn.org/stable/modules/ensemble.html). Ensemble is another word for multiple models put together to make a decision.\n",
    "\n",
    "One of the most common and useful ensemble methods is the [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest). Known for its fast training and prediction times and adaptibility to different problems.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen is a great read.\n",
    "\n",
    "Since we're working with regression, we'll use Scikit-Learn's [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "\n",
    "We can use the exact same workflow as above. Except for changing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IMPORTANT NOTES \n",
    "\n",
    "`model.score()` in above cell returns Cooefficient of Determination.\n",
    "\n",
    "\n",
    "## Cooefficient of Determination (R-Squared)\n",
    "\n",
    "\n",
    "R-Squared indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. R-Squared shows how well your predictions approximate the real data points. It’s like grading a test out of 100%. A high R-Squared (close to 1) means your model can very closely predict the actual values. For instance, in predicting house prices, a high R-Squared would indicate that your model captures most of the variability in house prices.\n",
    "\n",
    "The coefficient of determination (R²) is a number between 0 and 1 that measures how well a statistical model predicts an outcome. The outcome is represented by the model’s dependent variable (target variable).More technically, R2 is a measure of goodness of fit.\n",
    "\n",
    "Note: Classification Models (Logistic Regression/RandomForrestClassifier) return Mean Accuracy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Used Lasso model in practice session- the one which is shown in Scikit learn model choice cheat-sheet)\n",
    "\n",
    "\n",
    "## Ensemble methods\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "    \n",
    "\n",
    "The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "Two families of ensemble methods are usually distinguished: Average Method and Squential Method\n",
    "\n",
    "In averaging methods, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
    "\n",
    "Examples: Bagging methods, Forests of randomized trees\n",
    "\n",
    "By contrast, in boosting methods, base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "\n",
    "Examples: AdaBoost, Gradient Tree Boosting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (DTs) \n",
    "\n",
    "These are a non-parametric supervised learning method used for classification and regression. \n",
    "The goal is to create a model that predicts the value of a target variable \n",
    "by learning simple decision rules inferred from the data features\n",
    "\n",
    "https://www.ibm.com/topics/decision-trees\n",
    "\n",
    "It has a hierarchical, tree structure, which consists of a root node, branches, internal nodes and leaf nodes.\n",
    "\n",
    "As you can see from the diagram above, a decision tree starts with a root node, which does not have any incoming branches. The outgoing branches from the root node then feed into the internal nodes, also known as decision nodes. Based on the available features, both node types conduct evaluations to form homogenous subsets, which are denoted by leaf nodes, or terminal nodes. The leaf nodes represent all the possible outcomes within the dataset. \n",
    "\n",
    "\n",
    "A nice video about Regressive Decision Tree by Stat Quest- the same publisher has also a video about Classification Decision Tree\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=g9c66TUylZ4&t=0s&ab_channel=StatQuestwithJoshStarmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Random Forrest is the combination of lots of Desicion Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score metirc of regression aglorithms is R^2\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, we get a boost in score on the test set of over 0.2 with a change of model.\n",
    "\n",
    "At first, the diagram can seem confusing. But once you get a little practice applying different models to different problems, you'll start to pick up which sorts of algorithms do better with different types of data.\n",
    "\n",
    "### 2.2 Picking a machine learning model for a classification problem\n",
    "Now, let's check out the choosing process for a classification problem.\n",
    "\n",
    "Say you were trying to predict whether or not a patient had heart disease based on their medical records.\n",
    "\n",
    "The dataset in `../data/heart-disease.csv` contains data for just that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../project_files/data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many samples are there?\n",
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the California Housing dataset, here we want to use all of the available data to predict the target column (1 for if a patient has heart disease and 0 for if they don't).\n",
    "\n",
    "So what do we know?\n",
    "\n",
    "We've got 303 samples (1 row = 1 sample) and we're trying to predict whether or not a patient has heart disease.\n",
    "\n",
    "Because we're trying to predict whether each sample is one thing or another, we've got a classification problem.\n",
    "\n",
    "Let's see how it lines up with our [Scikit-Learn algorithm cheat-sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "<img src=\"../project_files/images/sklearn-ml-map-cheatsheet-heart-disease-linear-svc.png\" width=700/>\n",
    "\n",
    "Following the cheat-sheet we end up at [`LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) which stands for Linear Support Vector Classifier. Let's try it on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8688524590163934"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LinearSVC from the svm module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight out of the box (with no tuning or improvements) the model scores 47% accuracy, which with 2 classes (heart disease or not) is as good as guessing.\n",
    "\n",
    "With this result, we'll go back to our diagram and see what our options are.\n",
    "\n",
    "<img src=\"../images/sklearn-ml-map-cheatsheet-heart-disease-ensemble.png\" width=700/>\n",
    "\n",
    "Following the path (and skipping a few, don't worry, we'll get to this) we come up to [`EnsembleMethods`](https://scikit-learn.org/stable/modules/ensemble.html) again. Except this time, we'll be looking at ensemble classifiers instead of regressors.\n",
    "\n",
    "Remember our [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) from above? We'll it has a dance partner, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) which is an ensemble based machine model learning model for classification. You might be able to guess what we can use it for.\n",
    "\n",
    "Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `RandomForestClassifier` we get almost double the score of `LinearSVC`.\n",
    "\n",
    "One thing to remember, is both models are yet to receive any hyperparameter tuning. Hyperparameter tuning is fancy term for adjusting some settings on a model to try and make it better. It usually happens once you've found a decent baseline result you'd like to improve upon.\n",
    "\n",
    "In this case, we'd probably take the `RandomForestClassifier` and try and improve it with hyperparameter tuning (which we'll see later on).\n",
    "\n",
    "### What about the other models?\n",
    "\n",
    "Looking at the cheat-sheet and the examples above, you may have noticed we've skipped a few.\n",
    "\n",
    "Why?\n",
    "\n",
    "The first reason is time. Covering every single one would take a fair bit longer than what we've done here. And the second one is the effectiveness of ensemble methods.\n",
    "\n",
    "A little tidbit for modelling in machine learning is:\n",
    "\n",
    "* If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.\n",
    "* If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "* [Random Forest Wikipedia](https://en.wikipedia.org/wiki/Random_forest)\n",
    "* [Random Forests in Python](http://blog.yhat.com/posts/random-forests-in-python.html) by yhat\n",
    "* [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen\n",
    "\n",
    "### Experiment until something works\n",
    "\n",
    "The beautiful thing is, the way the Scikit-Learn API is designed, once you know the way with one model, using another is much the same.\n",
    "\n",
    "And since a big part of being a machine learning engineer or data scientist is experimenting, you might want to try out some of the other models on the cheat-sheet and see how you go. The more you can reduce the time between experiments, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model to data and using it to make predictions\n",
    "\n",
    "Now you've chosen a model, the next step is to have it learn from the data so it can be used for predictions in the future.\n",
    "\n",
    "If you've followed through, you've seen a few examples of this already.\n",
    "\n",
    "### 3.1 Fitting a model to data\n",
    "\n",
    "In Scikit-Learn, the process of having a machine learning model learn patterns from a dataset involves calling the `fit()` method and passing it data, such as, `fit(X, y)`.\n",
    "\n",
    "Where `X` is a feature array and `y` is a target array.\n",
    "\n",
    "Other names for `X` include:\n",
    "* Data\n",
    "* Feature variables\n",
    "* Features\n",
    "\n",
    "Other names for `y` include:\n",
    "* Labels\n",
    "* Target variable\n",
    "\n",
    "For supervised learning there is usually an `X` and `y`. For unsupervised learning, there's no `y` (no labels).\n",
    "\n",
    "Let's revisit the example of using patient data (`X`) to predict whether or not they have heart disease (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "Calling the `fit()` method will cause the machine learning algorithm to attempt to find patterns between `X` and `y`. Or if there's no `y`, it'll only find the patterns within `X`.\n",
    "\n",
    "Let's see `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `X` and `y` to `fit()` will cause the model to go through all of the examples in `X` (data) and see what their corresponding `y` (label) is.\n",
    "\n",
    "How the model does this is different depending on the model you use.\n",
    "\n",
    "Explaining the details of each would take an entire textbook. \n",
    "\n",
    "For now, you could imagine it similar to how you would figure out patterns if you had enough time. \n",
    "\n",
    "You'd look at the feature variables, `X`, the `age`, `sex`, `chol` (cholesterol) and see what different values led to the labels, `y`, `1` for heart disease, `0` for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "**During training (finding patterns in data):**\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "**During testing or in production (using learned patterns):**\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data.\n",
    "\n",
    "### 3.2 Making predictions using a machine learning model\n",
    "Now we've got a trained model, one which has hoepfully learned patterns in the data, you'll want to use it to make predictions.\n",
    "\n",
    "Scikit-Learn enables this in several ways. Two of the most common and useful are [`predict()`](https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/multiclass.py#L299) and [`predict_proba()`](https://github.com/scikit-learn/scikit-learn/blob/5f3c3f037/sklearn/linear_model/_logistic.py#L1617).\n",
    "\n",
    "Let's see them in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data in the form of `X`, the `predict()` function returns labels in the form of `y`.\n",
    "\n",
    "It's standard practice to save these predictions to a variable named something like `y_preds` for later comparison to `y_test` or `y_true` (usually same as `y_test` just another name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare predictions to truth\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of doing this is with Scikit-Learn's [`accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For the `predict()` function to work, it must be passed `X` (data) in the same format the model was trained on. Anything different and it will return an error.\n",
    "\n",
    "`predict_proba()` returns the probabilities of a classification label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return probabilities rather than labels; FIRST PROBABILITY OF ZERO THAN PRBABILITY OF ONE (0,1)\n",
    "\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return labels\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_proba()` returns an array of five arrays each containing two values.\n",
    "\n",
    "Each number is the probability of a label given a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find prediction probabilities for 1 sample\n",
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output means the sample `X_test[:1]`, the model is predicting label 0 (index 0) with a probability score of 0.89.\n",
    "\n",
    "Because the score is over 0.5, when using `predict()`, a label of 0 is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the label for 1 sample\n",
    "clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does 0.5 come from?\n",
    "\n",
    "Because our problem is a binary classification task (heart disease or not heart disease), predicting a label with 0.5 probability every time would be the same as a coin toss (guessing). Therefore, once the prediction probability of a sample passes 0.5, for a certain label, it's assigned that label.\n",
    "\n",
    "`predict()` can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3265721842781009"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It is the average absolute difference between the predicted and actual values\n",
    ".\n",
    "https://vitalflux.com/mse-vs-rmse-vs-mae-vs-mape-vs-r-squared-when-to-use/\n",
    "\n",
    "\n",
    "\n",
    "Now we've seen how to get a model how to find patterns in data using the `fit()` function and make predictions using what its learned using the `predict()` and `predict_proba()` functions, it's time to evaluate those predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating a model\n",
    "\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The `score()` method. Calling `score()` on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The `scoring` parameter. This parameter can be passed to methods such as [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) or [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the `scoring` parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 General model evaluation with `score()`\n",
    "\n",
    "If we bring down the code from our previous classification problem (building a classifier to predict whether or not someone has heart disease based on their medical records).\n",
    "\n",
    "We can see the `score()` method come into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been fit on the training data (`X_train`, `y_train`), we can call the `score()` method on it and evaluate our model on the test data, data the model has never seen before (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `clf` is an instance of `RandomForestClassifier`, the `score()` method uses mean accuracy as its score method.\n",
    "\n",
    "You can find this by pressing **SHIFT + TAB** within the brackets of `score()` when called on a model instance.\n",
    "\n",
    "Behind the scenes, `score()` makes predictions on `X_test` using the trained model and then compares those predictions to the actual labels `y_test`.\n",
    "\n",
    "A model which predicts everything 100% correct would receive a score of 1.0 (or 100%).\n",
    "\n",
    "Our model doesn't get everything correct, but at 85% (0.85 * 100), it's still far better than guessing.\n",
    "\n",
    "Let's do the same but with the regression code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the consistent design of the Scikit-Learn library, we can call the same `score()` method on `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066196804802649"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `model` is an instance of `RandomForestRegressor`. And since it's a regression model, the default metric built into `score()` is the coefficient of determination or R^2 (pronounced R-sqaured).\n",
    "\n",
    "Remember, you can find this by pressing **SHIFT + TAB** within the brackets of `score()` when called on a model instance.\n",
    "\n",
    "The best possible value here is 1.0, this means the model predicts the target regression values exactly.\n",
    "\n",
    "Calling the `score()` method on any model instance and passing it test data is a good quick way to see how your model is going.\n",
    "\n",
    "However, when you get further into a problem, it's likely you'll want to start using more powerful metrics to evaluate your models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating your models using the `scoring` parameter \n",
    "\n",
    "The next step up from using `score()` is to use a custom `scoring` parameter with [`cross_val_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) or [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "As you may have guessed, the `scoring` parameter you set will be different depending on the problem you're working on.\n",
    "\n",
    "We'll see some specific examples of different parameters in a moment but first let's check out `cross_val_score()`.\n",
    "\n",
    "To do so, we'll copy the heart disease classification code from above and then add another line at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `cross_val_score()` is slightly different to `score()`. Let's see a code example first and then we'll go through the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using score()\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.86885246, 0.81967213, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cross-validation.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "The first difference you might notice is `cross_val_score()` returns an array where as `score()` only returns a single number.\n",
    "\n",
    "`cross_val_score()` returns an array because of a parameter called `cv`, which stands for cross-validation.\n",
    "\n",
    "When `cv` isn't set, `cross_val_score()` will return an array of 3 numbers by default (or 5 by default if you're using Scikit-Learn version 0.22+).\n",
    "\n",
    "Remember, you can see the parameters of a function using **SHIFT + TAB** from within the brackets.\n",
    "\n",
    "But wait, you might be thinking, what even is cross-validation?\n",
    "\n",
    "A visual above might be able to help.\n",
    "\n",
    "We've dealt with Figure 1.0 before using `score(X_test, y_test)`. But looking deeper into this, if a model is trained using the training data or 80% of samples, this means 20% of samples aren't used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "Figure 2.0 shows 5-fold cross-validation, a method which tries to provide a solution to:\n",
    "\n",
    "1. Not training on all the data\n",
    "2. Avoiding getting lucky scores on single splits of the data\n",
    "\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "The actual name of this setup K-fold cross-validation. Where K is an abitrary number. We've used 5 because it looks nice visually, and will be the default in Scikit-Learn from version 0.22 onwards.\n",
    "\n",
    "Figure 2.0 is what happens when we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85245902, 0.80327869, 0.80327869, 0.76666667, 0.83333333])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-fold cross-validation\n",
    "cross_val_score(clf, X, y, cv=5) # cv is equivalent to K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set `cv=5` (5-fold cross-validation), we get back 5 different scores instead of 1.\n",
    "\n",
    "Taking the mean of this array gives us a more in-depth idea of how our model is performing by converting the 5 scores into one.\n",
    "\n",
    "Notice, the average `cross_val_score()` is slightly lower than single value returned by `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8043478260869565, 0.8184699453551912)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# Take mean of 5-fold cross-validation\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "clf_single_score, clf_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if you were asked to report the accuracy of your model, even though it's lower, you'd prefer the cross-validated metric over the non-cross-validated metric.\n",
    "\n",
    "Wait?\n",
    "\n",
    "We haven't used the `scoring` parameter at all.\n",
    "\n",
    "By default, it's set to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86885246, 0.80327869, 0.81967213, 0.78333333, 0.85      ])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, y, cv=5, scoring=None) # default scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `scoring` is set to `None` (by default), it uses the same metric as `score()` for whatever model is passed to `cross_val_score()`.\n",
    "\n",
    "In this case, our model is `clf` which is an instance of `RandomForestClassifier` which uses mean accuracy as the default `score()` metric.\n",
    "\n",
    "You can change the evaluation score `cross_val_score()` uses by changing the `scoring` parameter.\n",
    "\n",
    "And as you might have guessed, different problems call for different evaluation scores.\n",
    "\n",
    "The [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) outlines a vast range of evaluation metrics for different problems but let's have a look at a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "\n",
    "Four of the main evaluation metrics/methods you'll come across for classification models are:\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "Let's have a look at each of these. We'll bring down the classification code from above to go through some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "Accuracy is the default metric for the `score()` function within each of Scikit-Learn's classifier models. And it's probably the metric you'll see most often used for classification problems.\n",
    "\n",
    "However, we'll see in a second how it may not always be the best metric to use.\n",
    "\n",
    "Scikit-Learn returns accuracy as a decimal but you can easily convert it to a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Accuracy: 85.25%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy as percentage\n",
    "print(f\"Heart Disease Classifier Accuracy: {clf.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "If this one sounds like a mouthful, its because reading the full name is.\n",
    "\n",
    "It's usually referred to as AUC for Area Under Curve and the curve they're talking about is the Receiver Operating Characteristic or ROC for short.\n",
    "\n",
    "So if hear someone talking about AUC or ROC, they're probably talking about what follows.\n",
    "\n",
    "ROC curves are a comparison of true postive rate (tpr) versus false positive rate (fpr).\n",
    "\n",
    "For clarity:\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1\n",
    "\n",
    "Now we know this, let's see one. Scikit-Learn lets you calculate the information required for a ROC curve using the [`roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.06896552,\n",
       "       0.06896552, 0.10344828, 0.13793103, 0.13793103, 0.17241379,\n",
       "       0.17241379, 0.27586207, 0.4137931 , 0.48275862, 0.55172414,\n",
       "       0.65517241, 0.72413793, 0.72413793, 0.82758621, 1.        ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "# Keep the probabilites of the positive class only\n",
    "y_probs = y_probs[:, 1]\n",
    "\n",
    "# Calculate fpr, tpr and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Check the false positive rate\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these on their own doesn't make much sense. It's much easier to see their value visually. \n",
    "\n",
    "Since Scikit-Learn doesn't have a built-in function to plot a ROC curve, quite often, you'll find a function (or write your own) like the one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positve rate (fpr) and \n",
    "    true postive rate (tpr) of a classifier.\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    # Plot line with no predictive power (baseline)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--', label='Guessing')\n",
    "    # Customize the plot\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot for the first time, it might seem a bit confusing.\n",
    "\n",
    "The main thing to take away here is our model is doing far better than guessing.\n",
    "\n",
    "A metric you can use to quantify the ROC curve in a single number is AUC (Area Under Curve). Scikit-Learn implements a function to caculate this called [`roc_auc_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score). \n",
    "\n",
    "The maximum ROC AUC score you can achieve is 1.0 and generally, the closer to 1.0, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304956896551724"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most ideal position for a ROC curve to run along the top left corner of the plot. \n",
    "\n",
    "This would mean the model predicts only true positives and no false positives. And would result in a ROC AUC score of 1.0.\n",
    "\n",
    "You can see this by creating a ROC curve using only the `y_test` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot perfect ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perfect ROC AUC score\n",
    "roc_auc_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, a perfect ROC curve is unlikely.\n",
    "\n",
    "#### Confusion matrix\n",
    "The next way to evaluate a classification model is by using a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). \n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. In essence, giving you an idea of where the model is getting confused.\n",
    "\n",
    "A confusion matrix is a metric quick way to compare the labels a model predicts and the actual labels it was supposed to predict.\n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused.\n",
    "\n",
    "<img src=\"images/confusion-matrix-new.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  5],\n",
       "       [ 4, 28]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is probably easier visualized.\n",
    "\n",
    "One way to do it is with `pd.crosstab()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Label   0   1\n",
       "Actual Label           \n",
       "0                24   5\n",
       "1                 4  28"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, \n",
    "            y_preds, \n",
    "            rownames=[\"Actual Label\"], \n",
    "            colnames=[\"Predicted Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a confusion matrix using Scikit-Learn\n",
    "\n",
    "Scikit-Learn has multiple different implementations of plotting confusion matrices:\n",
    "\n",
    "1. [`sklearn.metrics.ConfusionMatrixDisplay.from_estimator(estimator, X, y)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_estimator) - this takes a fitted estimator (like our `clf` model), features (`X`) and labels (`y`), it then uses the trained estimator to make predictions on `X` and compares the predictions to `y` by displaying a confusion matrix.\n",
    "2. [`sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions) - this takes truth labels and predicted labels and compares them by displaying a confusion matrix.\n",
    "\n",
    "> **Note:** Both of these methods/classes require Scikit-Learn 1.0+. To check your version of Scikit-Learn run:\n",
    "```python\n",
    "import sklearn\n",
    "sklearn.__version__\n",
    "```\n",
    "> If you don't have 1.0+, you can upgrade at: https://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=clf, X=X, y=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix from predictions\n",
    "ConfusionMatrixDisplay.from_predictions(y_true=y_test, \n",
    "                                        y_pred=y_preds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report\n",
    "\n",
    "The final major metric you should consider when evaluating a classification model is a classification report.\n",
    "\n",
    "A classification report is more so a collection of metrics rather than a single one.\n",
    "\n",
    "You can create a classification report using Scikit-Learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function.\n",
    "\n",
    "Let's see one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        29\n",
      "           1       0.85      0.88      0.86        32\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns four columns: precision, recall, f1-score and support.\n",
    "\n",
    "The number of rows will depend on how many different classes there are. But there will always be three rows labell accuracy, macro avg and weighted avg.\n",
    "\n",
    "Each term measures something slightly different:\n",
    "* **Precision** - Indicates the proportion of positive identifications (model predicted class `1`) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "* **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "* **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "* **Support** - The number of samples each metric was calculated on.\n",
    "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "* **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into effect. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "* **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "When should you use each?\n",
    "\n",
    "It can be tempting to base your classification models perfomance only on accuracy. And accuracy is a good metric to report, except when you have very imbalanced classes.\n",
    "\n",
    "For example, let's say there were 10,000 people. And 1 of them had a disease. You're asked to build a model to predict who has it.\n",
    "\n",
    "You build the model and find your model to be 99.99% accurate. Which sounds great!\n",
    "...until you realise, all its doing is predicting no one has the disease, in other words all 10,000 predictions are false.\n",
    "\n",
    "In this case, you'd want to turn to metrics such as precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE\n",
    "\n",
    "                          precision recall    f1-score   support\n",
    "\n",
    "               Not Spam   0.92      0.95      0.93       500\n",
    "               Spam       0.80      0.70      0.75       100\n",
    "\n",
    "           accuracy                           0.89       600\n",
    "           macro avg      0.86      0.83      0.84       600\n",
    "           weighted avg   0.89      0.89      0.89       600\n",
    "\n",
    "\n",
    "\n",
    "****************\n",
    "Precision: For the “Not Spam” class, the precision is 0.92, indicating that 92% of the emails predicted as “Not Spam” are \n",
    "correct. For the “Spam” class, the precision is 0.80, meaning that 80% of the emails predicted as “Spam” are correct.\n",
    "\n",
    "****************\n",
    "Recall: The recall for the “Not Spam” class is 0.95, indicating that the model captures 95% of the actual “Not Spam”\n",
    "emails. For the “Spam” class, the recall is 0.70, meaning that the model captures only 70% of the actual “Spam” emails.\n",
    "\n",
    "****************\n",
    "F1-score: The F1-score for the “Not Spam” class is 0.93, balancing precision and recall. For the “Spam” class, the F1-score is 0.75.\n",
    "Support: The dataset contains 500 instances of “Not Spam” and 100 instances of “Spam.”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one case\n",
    "\n",
    "disease_preds = np.zeros(10000) # every prediction is 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true, \n",
    "                                   disease_preds, \n",
    "                                   output_dict=True,\n",
    "                                   zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here, we've got an accuracy of 0.9999 (99.99%), great precision and recall on class 0.0 but nothing for class 1.0.\n",
    "\n",
    "Ask yourself, although the model achieves 99.99% accuracy, is it useful?\n",
    "\n",
    "To summarize:\n",
    "* Accuracy is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1)\n",
    "* Precision and recall become more important when classes are imbalanced.\n",
    "* If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "* If false negative predictions are worse than false positives, aim for higher recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "Similar to classification, there are [several metrics you can use to evaluate your regression models](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics).\n",
    "\n",
    "We'll check out the following.\n",
    "\n",
    "1. **R^2 (pronounced r-squared) or coefficient of determination** - Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1. \n",
    "2. **Mean absolute error (MAE)** - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "3. **Mean squared error (MSE)** - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "\n",
    "Let's see them in action. First, we'll bring down our regression model code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R^2 Score (coefficient of determination)**\n",
    "\n",
    "Once you've got a trained regression model, the default evaluation metric in the `score()` function is R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065734772187598"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the models R^2 score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of the `score()` function, R^2 can be calculated using Scikit-Learn's [`r2_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score) function.\n",
    "\n",
    "A model which only predicted the mean would get a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())\n",
    "\n",
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a perfect model would get a score of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your regression models, you'll want to maximise R^2, whilst minimising MAE and MSE.\n",
    "\n",
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "A model's mean absolute error can be calculated with Scikit-Learn's [`mean_absolute_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32659871732073664"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our model achieves an MAE of 0.3265. This means, on average our models predictions are 0.3265 units away from the actual value.**\n",
    "\n",
    "Let's make it a little more visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20046</th>\n",
       "      <td>0.47700</td>\n",
       "      <td>0.493840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>0.45800</td>\n",
       "      <td>0.754940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>5.00001</td>\n",
       "      <td>4.928596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>2.18600</td>\n",
       "      <td>2.543160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>2.78000</td>\n",
       "      <td>2.331760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15362</th>\n",
       "      <td>2.63300</td>\n",
       "      <td>2.220380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>2.66800</td>\n",
       "      <td>1.947760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18086</th>\n",
       "      <td>5.00001</td>\n",
       "      <td>4.836378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>0.72300</td>\n",
       "      <td>0.717820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>1.51500</td>\n",
       "      <td>1.679010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual values  predictions\n",
       "20046        0.47700     0.493840\n",
       "3024         0.45800     0.754940\n",
       "15663        5.00001     4.928596\n",
       "20484        2.18600     2.543160\n",
       "9814         2.78000     2.331760\n",
       "...              ...          ...\n",
       "15362        2.63300     2.220380\n",
       "16623        2.66800     1.947760\n",
       "18086        5.00001     4.836378\n",
       "2144         0.72300     0.717820\n",
       "3665         1.51500     1.679010\n",
       "\n",
       "[4128 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"actual values\": y_test, \n",
    "                   \"predictions\": y_preds})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can the predictions are slightly different to the actual values.\n",
    "\n",
    "Depending what problem you're working on, having a difference like we do now, might be okay. On the flip side, it may also not be okay, meaning the predictions would have to be closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(0, len(df), 1)\n",
    "ax.scatter(x, df[\"actual values\"], c='b', label=\"Acutual Values\")\n",
    "ax.scatter(x, df[\"predictions\"], c='r', label=\"Predictions\")\n",
    "ax.legend(loc=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE)**\n",
    "\n",
    "How about MSE? We can calculate it with Scikit-Learn's [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2534678520824551"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE will always be higher than MAE because is squares the errors rather than only taking the absolute difference into account.\n",
    "\n",
    "Now you might be thinking, which regression evaluation metric should you use?\n",
    "\n",
    "* R^2 is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your R^2 value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "* MAE gives a better indication of how far off each of your model's predictions are on average.\n",
    "* As for MAE or MSE, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are). \n",
    "    * Pay more attention to MAE: When being \\$10,000 off is ***twice*** as bad as being \\$5,000 off.\n",
    "    * Pay more attention to MSE: When being \\$10,000 off is ***more than twice*** as bad as being \\$5,000 off.\n",
    "    \n",
    "**Note:** What we've covered here is only a handful of potential metrics you can use to evaluate your models. If you're after a complete list, check out the [Scikit-Learn metrics and scoring documentation](https://scikit-learn.org/stable/modules/model_evaluation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally using the `scoring` parameter\n",
    "\n",
    "Woah. We've covered a bunch but haven't even touched the `scoring` parameter...\n",
    "\n",
    "As a refresh, the `scoring` parameter can be used with a function like `cross_val_score()` to tell Scikit-Learn what evaluation metric to return using cross-validation.\n",
    "\n",
    "Let's check it out with our classification model and the heart disease dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use the default, which is mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen this before, now we got 5 different accuracy scores on different test splits of the data.\n",
    "\n",
    "Averaging this gives the cross-validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.48%\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the same using the `scoring` parameter and passing it `\"accuracy\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.48%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for the other metrics we've been using for classification.\n",
    "\n",
    "Let's try `\"precision\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated precision is: 0.83\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "print(f\"The cross-validated precision is: {np.mean(cv_precision):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about `\"recall\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated recall is: 0.85\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "print(f\"The cross-validated recall is: {np.mean(cv_recall):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `\"f1\"` (for F1 score)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated F1 score is: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_f1 = cross_val_score(clf, X, y, cv=5, scoring=\"f1\")\n",
    "print(f\"The cross-validated F1 score is: {np.mean(cv_f1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this process with our regression metrics.\n",
    "\n",
    "Let's revisit our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default is `\"r2\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R^2 score is: 0.65\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
    "print(f\"The cross-validated R^2 score is: {np.mean(cv_r2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can use `\"neg_mean_absolute_error\"` for MAE (mean absolute error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cv_mae = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "print(f\"The cross-validated MAE score is: {np.mean(cv_mae):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the `\"neg_\"`?\n",
    "\n",
    "Because Scikit-Learn documentation states:\n",
    "> [\"All scorer objects follow the convention that higher return values are better than lower return values.\"](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)\n",
    "\n",
    "Which in this case, means a lower negative value (closer to 0) is better.\n",
    "\n",
    "What about `\"neg_mean_squared_error\"` for MSE (mean squared error)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated MSE score is: -0.43\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_mse = cross_val_score(model, \n",
    "                         X, \n",
    "                         y, \n",
    "                         cv=5,\n",
    "                         scoring=\"neg_mean_squared_error\")\n",
    "print(f\"The cross-validated MSE score is: {np.mean(cv_mse):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Using different evaluation metrics with Scikit-Learn\n",
    "\n",
    "Remember the third way of evaluating Scikit-Learn functions?\n",
    "\n",
    "> 3. Problem-specific metric functions. Similar to how the `scoring` parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "Well, we've kind of covered this third way of using evaulation metrics with Scikit-Learn.\n",
    "\n",
    "In essence, all of the metrics we've seen previously have their own function in Scikit-Learn.\n",
    "\n",
    "They all work by comparing an array of predictions, usually called `y_preds` to an array of actual labels, usually called `y_test` or `y_true`.\n",
    "\n",
    "#### Classification functions\n",
    "For:\n",
    "* Accuracy we can use [`accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "* Precision we can use [`precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "* Recall we can use [`recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "* F1 we can use [`f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics on the test set:\n",
      "Accuracy: 85.25%\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Classifier metrics on the test set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds):.2f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for the regression problem.\n",
    "\n",
    "#### Regression metrics\n",
    "\n",
    "For:\n",
    "* R^2 we can use [`r2_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)\n",
    "* MAE (mean absolute error) we can use [`mean_absolute_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
    "* MSE (mean squared error) we can use [`mean_squared_error()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression model metrics on the test set:\n",
      "R^2: 0.81\n",
      "MAE: 0.33\n",
      "MSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Regression model metrics on the test set:\")\n",
    "print(f\"R^2: {r2_score(y_test, y_preds):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. We've covered a lot. But it's worth it. Because evaluating a model's predictions is paramount in any machine learning project.\n",
    "\n",
    "There's nothing worse than training a machine learning model and optimizing for the wrong evaluation metric.\n",
    "\n",
    "Keep the metrics and evaluation methods we've gone through when training your future models.\n",
    "\n",
    "If you're after extra reading, I'd go through the [Scikit-Learn documentation for evaluation metrics](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "\n",
    "Now we've seen some different metrics we can use to evaluate a model, let's see some ways we can improve those metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "First predictions = baseline predictions. First model = baseline model.\n",
    "\n",
    "From a data perspective:\n",
    "- Could we collect more data? (generally, the more data, the better)\n",
    "- Could we improve our data? (adding features etc)\n",
    "\n",
    "From a model perspective:\n",
    "- Is there a better model we could use?\n",
    "- Could we improve the current model?\n",
    "\n",
    "Hyperparameters vs. Parameters\n",
    "- Parameters = model find these patterns in data (like related Thetta values)\n",
    "\n",
    "- Hyperparameters = settings on a model you can adjust to (potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV\n",
    "\n",
    "\n",
    "<img src=\"images/hyperparameter-tuning.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets, training, validation and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/train-validate-test.jpg\" />\n",
    "\n",
    "<img src=\"images/tuning-hyperparameters-by-hand.jpg\" />\n",
    "\n",
    "We're going to try and adjust:\n",
    "\n",
    "- n_estimators\n",
    "- max_depth\n",
    "- max_features\n",
    "- min_samples_leaf\n",
    "- min_samples_split\n",
    "\n",
    "\n",
    "\n",
    "n_estimators: The number of decision trees in the random forest.\n",
    "\n",
    "max_depth: The number of splits that each decision tree is allowed to make. If the number of splits is too low, the model underfits the data and if it is too high the model overfits. Generally, we go with a max depth of 3, 5, or 7.\n",
    "\n",
    "max_features: The number of columns that are shown to each decision tree. The specific features that are passed to each decision tree can vary between each decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels\n",
    "    on a classification.\n",
    "\n",
    "\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "\n",
    "# Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split] # training set\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split] # validation set\n",
    "X_test, y_test = X[valid_split:], y[valid_split:] # test set\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline predictions - Practice exam\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 80.43%\n",
      "Precision: 0.83\n",
      "Recall: 0.80\n",
      "F1 score: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.83, 'recall': 0.8, 'f1': 0.82}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make baseline predictions - Final exam\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier on test set\n",
    "baseline_metrics = evaluate_preds(y_test, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evalute the 2nd classsifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "\n",
    "What is Random Forest Algorith and what their hyperpameters are?\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   3.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   2.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   3.3s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   3.5s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.82244898        nan 0.80620748        nan 0.80595238        nan\n",
      " 0.81428571 0.83886054        nan 0.81428571]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1) #n_jobs set the number of processors we want to dedicate to this ML model and -1 means \n",
    "                                        # you want to dedicate all of the processors \n",
    "\n",
    "    \n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid, \n",
    "                            n_iter=10, # number of models to try/ combinations of parameters to try\n",
    "                            cv=5,\n",
    "                            verbose=2) #verbose displays the progress of RandomizedSearchCV when it runs\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters - Final exam\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV will use all combinations \n",
    "\n",
    "\n",
    "#len(n_estimators) - 6\n",
    "#len(max_depth) - 5\n",
    "# len(max_features) - 2\n",
    "# len(min_samples_split) - 3\n",
    "# len(min_samples_leaf) - 3\n",
    "# cross validation - 5\n",
    "\n",
    "6*5*2*3*3*5 #all above params will result in 2700 combinations which will take lot of processing time, so we wil reduce this num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce search space of hyperparameter\n",
    "\n",
    "#we can take best params from RandomizedSearchCV and change the grid_2 params on that basis\n",
    "\n",
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "          'max_depth': [None],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(n_estimators) - 3\n",
    "# len(max_depth) - 1\n",
    "# len(max_features) - 2\n",
    "# len(min_samples_split) - 1\n",
    "# len(min_samples_leaf) - 2\n",
    "# cross validation - 5\n",
    "\n",
    "3*1*2*1*2*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\ai local\\practice_projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.82270408 0.81811224 0.82244898 0.82253401 0.82236395 0.81011905]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                      param_grid=grid_2, #no inter param here, as it will look for all hypterparam combination\n",
    "                      cv=5,\n",
    "                      verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clarification on usage of different X_train,y_train for comparision purpose\n",
    "\n",
    "\n",
    "(no of CV sets for clf were different than what were used for RandomizedSearchCV and GridSearchCV \n",
    "\n",
    "In the previous video, we compared the metric results of 3 different models. However, there was a small error.\n",
    "\n",
    "As always, when comparing models, you should be careful to make sure they're compared on the same splits of data.\n",
    "\n",
    "For example, let's say you have model_1 and model_2 which each differ slightly.\n",
    "\n",
    "If you want to compare and evaluate their results, model_1 and model_2 should both be trained on the same data (e.g. X_train and y_train) and their predictions should each be made on the same data, for example:\n",
    "\n",
    "model_1.fit(X_train, y_train) -> model_1.predict(X_test) -> model_1_preds\n",
    "\n",
    "model_2.fit(X_train, y_train) -> model_2.predict(X_test) -> model_2_preds\n",
    "\n",
    "Note the differences here being the two models and the 2 different sets of predictions which can be compared against each other.\n",
    "\n",
    "The example in the video followed these steps but since the data was split differently for the baseline model, the comparisons aren't fully correct.\n",
    "\n",
    "An example end-to-end notebook with the correct methodology has been created on Google Colab here:\n",
    "\n",
    "https://colab.research.google.com/drive/1ISey96a5Ag6z2CvVZKVqTKNWRwZbZl0m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained machine learning models\n",
    "\n",
    "Two ways to save and load machine learning models:\n",
    "1. With Python's pickle module\n",
    "2. With the joblib module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an extisting model to file\n",
    "pickle.dump(gs_clf, open(\"gs_random_random_forest_model_1.pkl\", \"wb\")) #wb: write binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_random_forest_model_1.pkl\", \"rb\")) #rb: read binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.77, 'recall': 0.86, 'f1': 0.81}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joblib**\n",
    "\n",
    "\n",
    "As per documentation of Scikit Learn, saving the trained models using joblib is more efficient specially there are big arrays or training sets are invloved  \n",
    "\n",
    "\n",
    "In Scikit-Learn, exporting and importing a trained model is known as model persistence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save model to file\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Improving model predictions through experimentation (hyperparameter tuning)\n",
    "\n",
    "The first predictions you make with a model are generally referred to as baseline predictions. The same goes with the first evaluation metrics you get. These are generally referred to as baseline metrics.\n",
    "\n",
    "Your next goal is to improve upon these baseline metrics.\n",
    "\n",
    "Two of the main methods to improve baseline metrics are from a data perspective and a model perspective.\n",
    "\n",
    "From a data perspective asks:\n",
    "* Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "* Could we improve our data? This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "\n",
    "From a model perspective asks:\n",
    "* Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), ensemble methods are generally considered more complex models)\n",
    "* Could we improve the current model? If the model you're using performs well straight out of the box, can the **hyperparameters** be tuned to make it even better?\n",
    "\n",
    "**Note:** Patterns in data are also often referred to as data parameters. The difference between parameters and hyperparameters is a machine learning model seeks to find parameters in data on its own, where as, hyperparameters are settings on a model which a user (you) can adjust.\n",
    "\n",
    "Since we have two existing datasets, we'll come at exploration from a model perspective.\n",
    "\n",
    "More specifically, we'll look at how we could improve our `RandomForestClassifier` and `RandomForestRegressor` models through hyperparameter tuning.\n",
    "\n",
    "What even are hyperparameters?\n",
    "\n",
    "Good question, let's check it out. First, we'll instantiate a `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you instantiate a model like above, you're using the default hyperparameters.\n",
    "\n",
    "These get printed out when you call the model instance and `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.77, 'recall': 0.86, 'f1': 0.81}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and evaluate joblib predictions\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps we want to do (all in one cell):\n",
    "\n",
    "- Fill missing data\n",
    "- Convert data to numbers\n",
    "- Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipeline\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\"cat\", categorical_transformer, categorical_features),\n",
    "                        (\"door\", door_transformer, door_feature),\n",
    "                        (\"num\", numeric_transformer, numeric_features)\n",
    "                    ])\n",
    "\n",
    "# Creating a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see things like `max_depth`, `min_samples_split`, `n_estimators`.\n",
    "\n",
    "Each of these is a hyperparameter of the `RandomForestClassifier` you can adjust. \n",
    "\n",
    "You can think of hyperparameters as being similar to dials on an oven. On the default setting your oven might do an okay job cooking your favourite meal. But with a little experimentation, you find it does better when you adjust the settings. \n",
    "\n",
    "<img src=\"../images/sklearn-hyperparameter-tuning-oven.png\" width=400/>\n",
    "\n",
    "The same goes for imporving a machine learning model by hyperparameter tuning. The default hyperparameters on a machine learning model may find patterns in data well. But there's a chance a adjusting the hyperparameters may improve a models performance.\n",
    "\n",
    "Every machine learning model will have different hyperparameters you can tune.\n",
    "\n",
    "You might be thinking, \"how the hell do I remember all of these?\"\n",
    "\n",
    "And it's a good question. It's why we're focused on the Random Forest. Instead of memorizing all of the hyperparameters for every model, we'll see how it's done with one. And then knowing these principles, you can apply them to a different model if needed.\n",
    "\n",
    "Reading the [Scikit-Learn documentation for the Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), you'll find they suggest trying to change `n_estimators` (the number of trees in the forest) and `min_samples_split` (the minimum number of samples required to split an internal node).\n",
    "\n",
    "We'll try tuning these as well as:\n",
    "* `max_features` (the number of features to consider when looking for the best split)\n",
    "* `max_depth` (the maximum depth of the tree)\n",
    "* `min_samples_leaf` (the minimum number of samples required to be at a leaf node)\n",
    "\n",
    "If this still sounds like a lot, the good news is, the process we're taking with the Random Forest and tuning its hyperparameters, can be used for other machine learning models in Scikit-Learn. The only difference is, with a different model, the hyperparameters you tune will be different.\n",
    "\n",
    "Adjusting hyperparameters is usually an experimental process to figure out which are best. As there's no real way of knowing which hyperparameters will be best when starting out.\n",
    "\n",
    "To get familar with hyparameter tuning, we'll take our RandomForestClassifier and adjust its hyperparameters in 3 ways.\n",
    "\n",
    "1. By hand\n",
    "2. Randomly with [RandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "3. Exhaustively with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand \n",
    "\n",
    "So far we've worked with training and test datasets.\n",
    "\n",
    "You train a model on a training set and evaluate it on a test dataset.\n",
    "\n",
    "But hyperparameter tuning introduces a thrid set, a validation set.\n",
    "\n",
    "Now the process becomes, train a model on the training data, (try to) improve its hyperparameters on the validation set and evaluate it on the test set.\n",
    "\n",
    "If our starting dataset contained 100 different patient records labels indicating who had heart disease and who didn't and we wanted to build a machine learning model to predict who had heart disease and who didn't, it might look like this:\n",
    "\n",
    "<img src=\"../images/sklearn-train-valid-test-annotated.png\" width=500/>\n",
    "\n",
    "Since we know we're using a `RandomForestClassifier` and we know the hyperparameters we want to adjust, let's see what it looks like.\n",
    "\n",
    "First, let's remind ourselves of the base parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're going to adjust:\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`\n",
    "\n",
    "We'll use the same code as before, except this time we'll create a training, validation and test split.\n",
    "\n",
    "With the training set containing 70% of the data and the validation and test sets each containing 15%.\n",
    "\n",
    "Let's get some baseline results, then we'll tune the model.\n",
    "\n",
    "And since we're going to be evaluating a few models, let's make an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2), \n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1 score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[valid_split:]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.5s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   4.5s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   4.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   4.6s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   4.2s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   4.7s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   4.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   4.2s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   4.9s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   5.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   5.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   3.7s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   3.5s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   3.3s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   3.4s\n",
      "[CV] END model__max_depth=None, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   3.4s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.6s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.7s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.3s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.2s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.2s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.0s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.3s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.2s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.1s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.0s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.0s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.8s\n",
      "[CV] END model__max_depth=5, model__max_features=5, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Make&#x27;,\n",
       "                                                                          &#x27;Colour&#x27;]),\n",
       "                                                                        (&#x27;door&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;))]),\n",
       "                                                                         [&#x27;Doors&#x27;]),\n",
       "                                                                        (&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Odometer &#x27;\n",
       "                                                                          &#x27;(KM)&#x27;])])),\n",
       "                                       (&#x27;model&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [None, 5],\n",
       "                         &#x27;model__max_features&#x27;: [5],\n",
       "                         &#x27;model__min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;model__n_estimators&#x27;: [100, 1000],\n",
       "                         &#x27;preprocessor__num__imputer__strategy&#x27;: [&#x27;mean&#x27;,\n",
       "                                                                  &#x27;median&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Make&#x27;,\n",
       "                                                                          &#x27;Colour&#x27;]),\n",
       "                                                                        (&#x27;door&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;))]),\n",
       "                                                                         [&#x27;Doors&#x27;]),\n",
       "                                                                        (&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Odometer &#x27;\n",
       "                                                                          &#x27;(KM)&#x27;])])),\n",
       "                                       (&#x27;model&#x27;, RandomForestRegressor())]),\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [None, 5],\n",
       "                         &#x27;model__max_features&#x27;: [5],\n",
       "                         &#x27;model__min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;model__n_estimators&#x27;: [100, 1000],\n",
       "                         &#x27;preprocessor__num__imputer__strategy&#x27;: [&#x27;mean&#x27;,\n",
       "                                                                  &#x27;median&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Make&#x27;, &#x27;Colour&#x27;]),\n",
       "                                                 (&#x27;door&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=4,\n",
       "                                                                                 strategy=&#x27;constant&#x27;))]),\n",
       "                                                  [&#x27;Doors&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;Odometer (KM)&#x27;])])),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Make&#x27;, &#x27;Colour&#x27;]),\n",
       "                                (&#x27;door&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=4,\n",
       "                                                                strategy=&#x27;constant&#x27;))]),\n",
       "                                 [&#x27;Doors&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                 [&#x27;Odometer (KM)&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Make&#x27;, &#x27;Colour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">door</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Doors&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=4, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Odometer (KM)&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Make',\n",
       "                                                                          'Colour']),\n",
       "                                                                        ('door',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy='constant'))]),\n",
       "                                                                         ['Doors']),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Odometer '\n",
       "                                                                          '(KM)'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': [5],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV with our regression Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [5], #the default code in lecture was \"auto\" whcih threw errors and suggested to put interger\n",
    "    \"model__min_samples_split\": [2, 4]    \n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3135938685564946"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, now let's try and improve the results.\n",
    "\n",
    "We'll change 1 of the hyperparameters, `n_estimators` to 100 and see if it improves on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evaluate the 2nd classifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Slightly worse precision by slightly better recall and f1.\n",
    "\n",
    "How about we try another parameter?\n",
    "\n",
    "Wait...\n",
    "\n",
    "This could take a while if all we're doing is building new models with new hyperparameters each time.\n",
    "\n",
    "Surely there's a better way?\n",
    "\n",
    "There is.\n",
    "\n",
    "### 5.2 Hyperparameter tuning with [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "Scikit-Learn's [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) allows us to randomly search across different hyperparameters to see which work best. It also stores details about the ones which work best!\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "First, we create a grid (dictionary) of hyperparameters we'd like to search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid RandomizedSearchCV will search over\n",
    "grid = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\": [None, 5, 10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\": [2, 4, 6],\n",
    "        \"min_samples_leaf\": [1, 2, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where did these values come from?\n",
    "\n",
    "They're made up.\n",
    "\n",
    "Made up?\n",
    "\n",
    "Yes. Not completely pulled out of the air but after reading the [Scikit-Learn documentation on Random Forest's](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) you'll see some of these values have certain values which usually perform well and certain hyperparameters take strings rather than integers.\n",
    "\n",
    "Now we've got the grid setup, Scikit-Learn's `RandomizedSearchCV` will look at it, pick a random value from each, instantiate a model with those values and test each model.\n",
    "\n",
    "How many models will it test?\n",
    "\n",
    "As many as there are for each combination of hyperparameters to be tested. Let's add them up.\n",
    "\n",
    "`max_depth` has 4, `max_features` has 2, `min_samples_leaf` has 3, `min_samples_split` has 3, `n_estimators` has 5. That's 4x2x3x3x5 = 360 models!\n",
    "\n",
    "Or...\n",
    "\n",
    "We can set the `n_iter` parameter to limit the number of models `RandomizedSearchCV` tests.\n",
    "\n",
    "The best thing? The results we get will be cross-validated (hence the CV in `RandomizedSearchCV`) so we can use `train_test_split()`.\n",
    "\n",
    "And since we're going over so many different models, we'll set `n_jobs` to -1 of [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) so Scikit-Learn takes advantage of all the cores (processors) on our computers.\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "**Note:** Depending on `n_iter` (how many models you test), the different values in the hyperparameter grid, and the power of your computer, running the cell below may take a while.\n",
    "\n",
    "**Note 2:** Setting `n_jobs=-1` seems to be breaking on some machines (for me at least, as of 8 December 2019). There seems to be an issue about it, being tracked on GitHub. For the timebeing, `n_jobs=1` seems to be working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1000; total time=   0.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20, # try 20 models total\n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # print out results\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `RandomizedSearchCV` goes through `n_iter` combinations of of hyperparameter search space, it stores the best ones in the attribute `best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best hyperparameters found by RandomizedSearchCV\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we call `predict()` on `rs_clf` (our `RandomizedSearchCV` version of our classifier), it'll use the best hyperparameters it found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 83.61%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Thanks to `RandomizedSearchCV` testing out a bunch of different hyperparameters, we get a nice boost to all of the evaluation metrics for our classification model.\n",
    "\n",
    "There's one more way we could try to improve our model's hyperparamters. And it's with [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "### 5.3 Hyperparameter tuning with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "The main difference between `GridSearchCV` and `RandomizedSearchCV` is `GridSearchCV` searches across a grid of hyperparamters exhaustively, where as, `RandomizedSearchCV` searches across a grid of hyperparameters randomly (stopping after `n_iter` combinations).\n",
    "\n",
    "For example, let's see our grid of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomizedSearchCV` try `n_iter` combinations of different values. Where as, `GridSearchCV` will try every single possible combination. \n",
    "\n",
    "And if you remember from before when we did the calculation: `max_depth` has 4, `max_features` has 2, `min_samples_leaf` has 3, `min_samples_split` has 3, `n_estimators` has 5. \n",
    "\n",
    "That's 4x2x3x3x5 = 360 models!\n",
    "\n",
    "This could take a long time depending on the power of the computer you're using, the amount of data you have and the complexity of the hyperparamters (usually higher values means a more complex model).\n",
    "\n",
    "In our case, the data we're using is relatively small (only ~300 samples).\n",
    "\n",
    "Since we've already tried to find some ideal hyperparameters using `RandomizedSearchCV`, we'll create another hyperparameter grid based on the `best_params_` of `rs_clf`* with less options and then try to use `GridSearchCV` to find a more ideal set.\n",
    "\n",
    "**Note:** Based on the `best_params_` of `rs_clf` implies the next set of hyperparameters we'll try are roughly in the same range of the best set found by `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another hyperparameter grid similar to rs_clf.best_params_\n",
    "grid_2 = {'n_estimators': [1200, 1500, 2000],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'min_samples_split': [4, 6],\n",
    "          'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created another grid of hyperparameters to search over, this time with less total.\n",
    "\n",
    "`n_estimators` has 3, `max_depth` has 3, `max_features` has 2, `min_samples_leaf` has 2, `min_samples_split` has 2. \n",
    "\n",
    "That's 3x3x2x2x2 = 72 models in total. Or about 5 times less (360/72) combinations of hyperparameters less than our original grid.\n",
    "\n",
    "Now when we run `GridSearchCV`, passing it our classifier (`clf`), paramter grid (`grid_2`) and the number of cross-validation folds we'd like to use (`cv`), it'll create a model with every single combination of hyperparameters, 72 in total, and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1200; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=1500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1200; total time=   0.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=1500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=2000; total time=   1.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                      param_grid=grid_2,\n",
    "                      cv=5, # 5-fold cross-validation\n",
    "                      verbose=2) # print out progress\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it completes, we can check the best hyperparameter combinations it found using the `best_params_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best hyperparameters found with GridSearchCV\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by default when we call the `predict()` function on `gs_clf`, it'll use the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 83.61%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Max predictions with the GridSearchCV classifier\n",
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a DataFrame to compare the different metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems, even after trying 72 different combinations of hyperparamters, we don't get an improvement in results.\n",
    "\n",
    "These things might happen. But it's important to remember, it's not over. There may be more we can do.\n",
    "\n",
    "In a hyperparameter tuning sense, there may be a better set we could find through more extensive searching with RandomizedSearchCV and GridSearchCV but it's likely these improvements will be marginal.\n",
    "\n",
    "A few next ideas you could try:\n",
    "* Collecting more data - Based on the results our models are getting now, it seems like they're finding some patterns. Collecting more data may improve a models ability to find patterns. However, your ability to do this will largely depend on the project you're working on.\n",
    "* Try a more advanced model - Although our tuned Random Forest model is doing pretty well, a more advanced ensemble method such as [XGBoost](https://xgboost.ai/) or [CatBoost](https://catboost.ai/) might perform better.\n",
    "\n",
    "Since machine learning is part engineering, part science, these kind of experiments are common place in any machine learning project.\n",
    "\n",
    "Now you've got a somewhat tuned Random Forest model, the next thing you might want to do is export it and save it so you could share it with your team or use it in an application without having to retrain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained machine learning models\n",
    "\n",
    "Since our `GridSearchCV` model has the best results so far, we'll export it and save it to file.\n",
    "\n",
    "### 6.1 Saving and loading a model with [`pickle`](https://docs.python.org/3/library/pickle.html)\n",
    "\n",
    "We saw right at the start, one way to save a model is using Python's [`pickle` module](https://docs.python.org/3/library/pickle.html).\n",
    "\n",
    "We'll use `pickle`'s `dump()` function and pass it our model, `gs_clf`, along with the `open()` function containing a string for the filename we want to save our model as, along with the `\"wb\"` string which stands for \"write binary\", which is the file type `open()` will write our model as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(gs_clf, open(\"gs_random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's saved, we can import it using `pickle`'s `load()` function, passing it `open()` containing the filename as a string and `\"rb\"` standing for \"read binary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've reimported your trained model using `pickle`, you can use it to make predictions as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 83.61%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84, 'precision': 0.78, 'recall': 0.89, 'f1': 0.83}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions and evaluate the loaded model\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the reimported model evaluation metrics are the same as the model before we exported it.\n",
    "\n",
    "### 6.2 Saving and loading a model with [`joblib`](https://joblib.readthedocs.io/en/latest/persistence.html)\n",
    "\n",
    "The other way to load and save models is with `joblib`. Which works relatively the same as `pickle`.\n",
    "\n",
    "To save a model, we can use `joblib`'s `dump()` function, passing it the model (`gs_clf`) and the desired filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save a model to file\n",
    "dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've saved a model using `dump()`, you can import it using `load()` and passing it the filename of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loaded_joblib_model = load(filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, once imported, we can make predictions with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 83.61%\n",
      "Precision: 0.78\n",
      "Recall: 0.89\n",
      "F1 score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84, 'precision': 0.78, 'recall': 0.89, 'f1': 0.83}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and evaluate joblib predictions \n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the evaluation metrics are the same as before.\n",
    "\n",
    "Which one should you use, `pickle` or `joblib`?\n",
    "\n",
    "According to [Scikit-Learn's documentation](https://scikit-learn.org/stable/modules/model_persistence.html), they suggest it may be more efficient to use `joblib` as it's more efficient with large numpy array (which is what may be contained in trained/fitted Scikit-Learn models).\n",
    "\n",
    "Either way, they both function fairly similar so deciding on which one to use, shouldn't cause too much of an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Revisit the pipeline one more time, knowing what we know now\n",
    "\n",
    "We've covered a lot. And so far, it seems to be all over the place, which it is. But not to worry, machine learning projects often start out like this. A whole bunch of experimenting and code all over the place at the start and then once you've found something which works, the refinement process begins.\n",
    "\n",
    "What would this refinement process look like?\n",
    "\n",
    "We'll use the car sales regression problem (predicting the sale price of cars) as an example.\n",
    "\n",
    "To tidy things up, we'll be using Scikit-Learn's [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class. You can imagine `Pipeline` as being a way to string a number of different Scikit-Learn processes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Creating a regression [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "You might recall when, way back in Section 2: Getting Data Ready, we dealt with the car sales data, to build a regression model on it, we had to encode the categorical features into numbers and fill the missing data.\n",
    "\n",
    "The code we used worked, but it was a bit all over the place. Good news is, `Pipeline` can help us clean it up.\n",
    "\n",
    "Let's remind ourselves what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 1000 rows, three features are categorical (`Make`, `Colour`, `Doors`), the other two are numerical (`Odometer (KM)`, `Price`) and there's 249 missing values.\n",
    "\n",
    "We're going to have to turn the categorical features into numbers and fill the missing values before we can fit a model.\n",
    "\n",
    "We'll build a [`Pipeline()`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to do so.\n",
    "\n",
    "`Pipeline()`'s main input is `steps` which is a list (`[(step_name, action_to_take)]`) of the step name, plus the action you'd like it to perform.\n",
    "\n",
    "In our case, you could think of the steps as:\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data\n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop the rows with missing labels\n",
    "data = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transformer pipelines\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_features)])\n",
    "\n",
    "# Create a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done is combine a series of data preprocessing steps (filling missing values, encoding numerical values) as well as a model into a `Pipeline()`.\n",
    "\n",
    "Doing so not only cleans up the code, it ensures the same steps are taken every time the code is run rather than having multiple different processing steps happening in different stages.\n",
    "\n",
    "It's also possible to `GridSearchCV` or `RandomizedSearchCV` with a `Pipeline`.\n",
    "\n",
    "The main difference is when creating a hyperparameter grid, you have to add a prefix to each hyperparameter.\n",
    "\n",
    "The prefix is the name of the `Pipeline` step you'd like to alter, followed by two underscores.\n",
    "\n",
    "For example, to adjust `n_estimators` of `\"model\"` in the `Pipeline`, you'd use: `\"model__n_estimators\"`.\n",
    "\n",
    "Let's see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.0s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.8s\n",
      "[CV] END model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.1s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Make',\n",
       "                                                                          'Colour']),\n",
       "                                                                        ('door',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy='constant'))]),\n",
       "                                                                         ['Doors']),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Odometer '\n",
       "                                                                          '(KM)'])])),\n",
       "                                       ('model', RandomForestRegressor())]),\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto', 'sqrt'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using grid search with pipeline\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.292308819012865"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the best model\n",
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! Using `GridSearchCV` we see a nice boost in our models score. And the best thing is, because it's all in a `Pipeline`, we could easily replicate these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to next?\n",
    "\n",
    "If you've made it this far, congratulations! You've covered a lot of ground in the Scikit-Learn library.\n",
    "\n",
    "As you might've guessed, there's a lot more that hasn't been covered.\n",
    "\n",
    "But for the time being, you should be equipped with some of the most useful features of the library to start trying to apply them to your own problems.\n",
    "\n",
    "Somewhere you might like to look next is to apply what you've learned above to a Kaggle competition. Kaggle competitions are great places to practice your data science and machine learning skills and compare your results with others.\n",
    "\n",
    "A great idea would be to try to combine the heart disease classification code, as well as the `Pipeline` code, to build a model for the [Titanic dataset](https://www.kaggle.com/c/titanic).\n",
    "\n",
    "Otherwise, if you'd like to figure out what else the Scikit-Learn library is capable, [check out the documentation](https://scikit-learn.org/stable/user_guide.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
